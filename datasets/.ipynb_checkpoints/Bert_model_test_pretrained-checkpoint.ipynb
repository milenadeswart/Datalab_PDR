{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code aangepast van https://colab.research.google.com/github/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb#scrollTo=Dg82ndBA5xlN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at GroNLP/bert-base-dutch-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at GroNLP/bert-base-dutch-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# gebruik pretrained model (cased!): https://huggingface.co/GroNLP/bert-base-dutch-cased\n",
    "from transformers import AutoTokenizer, AutoModel, TFAutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/bert-base-dutch-cased\")\n",
    "model = AutoModel.from_pretrained(\"GroNLP/bert-base-dutch-cased\")  # PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inladen data\n",
    "dataset_path = \"~/share/Milena/programma-discriminatie-en-racisme/datasets/\"\n",
    "dataset_zoek = pd.read_csv(dataset_path + 'dataset_met_zoekwoorden.csv')[0:400] # model is te groot om te trainen met volledige dataset zonder GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'bestandsmap', 'bestandsnaam', 'pagina', 'paragraaf',\n",
      "       'text', 'discriminatie (ja/nee)?', 'aantal discriminerende woorden',\n",
      "       'discriminerende woorden'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    394\n",
       "1      6\n",
       "Name: discriminatie (ja/nee)?, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hoe veel komt discriminatie voor in de dataset?\n",
    "print(dataset_zoek.columns)\n",
    "\n",
    "dataset_zoek['discriminatie (ja/nee)?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 512)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenization, padding, masking\n",
    "# LET OP: TRUNCATION = TRUE KORT DE ZINNEN IN TOT MAX. 512 TEKENS. NOG BESPREKEN\n",
    "tokenized = dataset_zoek['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, truncation = True)))\n",
    "\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "\n",
    "np.array(padded).shape\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainen\n",
    "input_ids = torch.tensor(padded)  \n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "features = last_hidden_states[0][:,0,:].numpy()\n",
    "\n",
    "labels = dataset_zoek['discriminatie (ja/nee)?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset in train, test\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainen model (logistic regression)\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testen (logistic model)\n",
    "lr_clf.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at wietsedv/bert-base-dutch-cased-finetuned-sentiment were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# sentiment analysis\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"wietsedv/bert-base-dutch-cased-finetuned-sentiment\")\n",
    "model = AutoModel.from_pretrained(\"wietsedv/bert-base-dutch-cased-finetuned-sentiment\")  # PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      TER ONDERTEKENING                             ...\n",
      "1      Datum                                         ...\n",
      "2                                             Referentie\n",
      "3      Bijlagen                                      ...\n",
      "4      Intern OCW afgestemd                          ...\n",
      "                             ...                        \n",
      "395    3 Digitaal afstandsonderwijs Informatie voor o...\n",
      "396         1. \u0007Wat kan ik van de     school verwachten?\n",
      "397    Als uw kind tijdelijk niet of minder naar scho...\n",
      "398    Hulp op maat De eerste stap die de school moet...\n",
      "399    Regels voor digitaal afstandsonderwijs Digitaa...\n",
      "Name: text, Length: 400, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataset_zoek['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'neg', 'score': 0.9999552965164185}, {'label': 'pos', 'score': 4.473637090995908e-05}]]\n",
      "realiseren van een bestendige studiekeuze en het voorkomen van uitval en studiewissel. De insteek is dat lopende oriÃ«ntatietrajecten met relatief kleine aanpassingen aan de wettelijke vereisten kunnen voldoen en dus in ieder geval gedurende de pilot inhoudelijk doorgang kunnen vinden. Deze aanpassingen zitten dan veelal op het vlak van de toepassing van het toelatingsrecht en het opleidingsdomein als inschrijfpositie.\n",
      "[[{'label': 'neg', 'score': 0.9998977184295654}, {'label': 'pos', 'score': 0.00010232756903860718}]]\n",
      "Pagina 2 van 2\n",
      "[[{'label': 'neg', 'score': 0.004039074759930372}, {'label': 'pos', 'score': 0.9959608912467957}]]\n",
      "TER ONDERTEKENING                                                                           Hoger Onderwijs en                                                                                             Studiefinanciering Aan: MOCW                                                                                             Van                                                                                                   Persoonsgegeven                                                                                                 Persoonsgegeven\n",
      "[[{'label': 'neg', 'score': 2.1844893126399256e-05}, {'label': 'pos', 'score': 0.9999781847000122}]]\n",
      "Datum                                                                                             12 januari 2024\n",
      "[[{'label': 'neg', 'score': 8.580077701481059e-05}, {'label': 'pos', 'score': 0.9999141693115234}]]\n",
      "Referentie                                                                                             43604175\n",
      "[[{'label': 'neg', 'score': 0.999797523021698}, {'label': 'pos', 'score': 0.0002025084977503866}]]\n",
      "Bijlagen                                                                                             1                            Kamervragen over het bericht: 'Ramen                            Universiteitsbibliotheek vernield en beklad met pro-                            Palestinaleuzenâ\n",
      "[[{'label': 'neg', 'score': 0.995886504650116}, {'label': 'pos', 'score': 0.004113445524126291}]]\n",
      "Aanleiding Naar aanleiding van verschillende berichten in de media hebben de leden Blaauw en Faber-van de Klashorst (beiden PVV) Kamervragen gesteld over de                                                              1 vernielingen bij de Rijksuniversiteit Groningen (RUG).\n",
      "[[{'label': 'neg', 'score': 0.005062310490757227}, {'label': 'pos', 'score': 0.9949376583099365}]]\n",
      "Geadviseerd besluit U wordt geadviseerd om de bijgevoegde antwoorden te ondertekenen. Na ondertekening worden de antwoorden naar de Tweede Kamer verzonden.\n",
      "[[{'label': 'neg', 'score': 3.4204097119072685e-06}, {'label': 'pos', 'score': 0.999996542930603}]]\n",
      "Kernpunten In de antwoorden zijn de inzichten meegenomen uit gesprekken die u sinds het begin van het conflict in IsraÃ«l en de Palestijnse gebieden in verschillende samenstellingen hebt gevoerd met docenten, studenten, bestuurders en organisaties uit de sectoren waar u verantwoordelijk voor bent. De beantwoording van deze vragen is in lijn met eerdere beantwoording van de drie sets Kamervragen van de SGP, PVV en BBB waarvoor contact is geweest met Min JenV, Min SZW en het OM.\n",
      "[[{'label': 'neg', 'score': 0.999769389629364}, {'label': 'pos', 'score': 0.00023064060951583087}]]\n",
      "Samenvatting van de lijn die u kiest in uw antwoorden In uw antwoorden schrijft u onder meer dat:     Â·    U deze openlijke vernieling onacceptabel vindt en dat deze geen enkele          bijdrage levert aan oplossingen voor de situatie in het Midden-Oosten.     Â·    Vernieling een misdrijf is en strafbaar is gesteld in artikel 350 van het          Wetboek van Strafrecht.     Â·    Het van groot belang is dat de discussie over dit conflict op een          respectvolle en waardige manier wordt gevoerd.     Â·    U het standpunt en handelen van de RUG onderschrijft en geen aanleiding          ziet om samen met het CvB hierover in gesprek te gaan. Het is in de          eerste plaats aan de universiteit om dergelijke casuÃ¯stiek proportioneel af\n",
      "[[{'label': 'neg', 'score': 4.367596375232097e-06}, {'label': 'pos', 'score': 0.9999955892562866}]]\n",
      "1  [1] RTV Noord, 13 december 2023: âRamen Universiteitsbibliotheek vernield en beklad met pro-Palestinaleuzenâ. https://www.rtvnoord.nl/nieuws/1102281/ramen- universiteitsbibliotheek-vernield-en-beklad-met-pro-palestinaleuzen-update\n",
      "[[{'label': 'neg', 'score': 0.00027769082225859165}, {'label': 'pos', 'score': 0.9997223019599915}]]\n",
      "[2] Dagblad van het Noorden, 13 december 2023: âRuiten Universiteitsbibliotheek Groningen vernield en beklad met pro-Palestinaleuzen. âWe will escalateââ. https://dvhn.nl/groningen/stad/Ruiten-van-Universiteitsbibliotheek-vernield-en-beklad- met-pro-Palestina-leuzen-28802458.html                                                                                             Pagina 1 van 2\n",
      "[[{'label': 'neg', 'score': 5.023719495511614e-06}, {'label': 'pos', 'score': 0.9999949932098389}]]\n",
      "te handelen, daar waar nodig de daartoe bevoegde partijen in te          schakelen en bij strafbare feiten aangifte te doen bij de politie.     Â·    U verwijst ook naar de gesprekken die u met het onderwijsveld voert over          de maatschappelijke spanning en de impact van het conflict, die u helpen          om een vinger aan de pols te blijven houden bij verdere ontwikkelingen in          het onderwijsveld.\n",
      "[[{'label': 'neg', 'score': 0.9999123811721802}, {'label': 'pos', 'score': 8.757544856052846e-05}]]\n",
      "Informatie die niet openbaar gemaakt kan worden N.v.t.\n",
      "[[{'label': 'neg', 'score': 0.9998977184295654}, {'label': 'pos', 'score': 0.00010232756903860718}]]\n",
      "Pagina 2 van 2\n",
      "[[{'label': 'neg', 'score': 0.9980023503303528}, {'label': 'pos', 'score': 0.0019976231269538403}]]\n",
      "TER BESLUITVORMING                                                                  Onderwijsprestaties en                                                                                     Voortgezet Onderwijs Aan: MPVO                                                                                     Van                                                                                      Persoonsgeg...                                                                                     T Persoonsgegeven\n",
      "[[{'label': 'neg', 'score': 1.7466825738665648e-05}, {'label': 'pos', 'score': 0.999982476234436}]]\n",
      "Datum                                                                                     10 januari 2024\n",
      "[[{'label': 'neg', 'score': 0.9952801465988159}, {'label': 'pos', 'score': 0.004719906020909548}]]\n",
      "Referentie                                                                                     43520273\n",
      "[[{'label': 'neg', 'score': 0.9570502638816833}, {'label': 'pos', 'score': 0.04294966906309128}]]\n",
      "Bijlagen                                                                                     Kamerbrief                            Tweede herstelonderzoek ISA                                                                                     Rapport Inspectie\n",
      "[[{'label': 'neg', 'score': 3.184558590874076e-05}, {'label': 'pos', 'score': 0.9999681711196899}]]\n",
      "Aanleiding Op vrijdag 5 januari heeft de Inspectie van het Onderwijs (hierna: de inspectie) een specifiek onderzoek gepubliceerd naar kwaliteit van het bestuurlijk handelen en het onderzoek naar financieel beheer van de Stichting Islamitische School Amsterdam (hierna: ISA).\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"text-classification\", model=\"wietsedv/bert-base-dutch-cased-finetuned-sentiment\", return_all_scores=True)\n",
    "\n",
    "for i in range(10, 30):\n",
    "    print(pipe(dataset_zoek.loc[i, 'text']))\n",
    "    print(dataset_zoek.loc[i, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'question' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-6d1b7dbada2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_input_ref_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_token_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep_token_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_token_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_token_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_input_ref_token_type_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_position_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_input_ref_pos_id_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'question' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-1594ae02dd4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m start_scores, end_scores = predict(input_ids, \\\n\u001b[0m\u001b[1;32m      2\u001b[0m                                    \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                    \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                    attention_mask=attention_mask)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predict' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot use a string pattern on a bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-8933aa351fc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLimeTextExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/lime/lime_text.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[0;34m(self, text_instance, classifier_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[1;32m    409\u001b[0m                           IndexedString(text_instance, bow=self.bow,\n\u001b[1;32m    410\u001b[0m                                         \u001b[0msplit_expression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_expression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m                                         mask_string=self.mask_string))\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0mdomain_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextDomainMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexed_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         data, yss, distances = self.__data_labels_distances(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/lime/lime_text.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, raw_string, split_expression, bow, mask_string)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# the separator character from the split results.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0msplitter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'(%s)|$'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msplit_expression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0mnon_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot use a string pattern on a bytes-like object"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataLabDisc",
   "language": "python",
   "name": "datalabdisc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
