{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code aangepast van https://www.philschmid.de/bert-text-classification-in-a-different-language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import pyarrow\n",
    "import transformers as ppb\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "import accelerate\n",
    "import evaluate\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at GroNLP/bert-base-dutch-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at GroNLP/bert-base-dutch-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# gebruik pretrained model (cased!): https://huggingface.co/GroNLP/bert-base-dutch-cased\n",
    "from transformers import AutoTokenizer, AutoModel, TFAutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/bert-base-dutch-cased\")\n",
    "model = AutoModel.from_pretrained(\"GroNLP/bert-base-dutch-cased\")  # PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inladen data\n",
    "dataset_path = \"~/share/Milena/programma-discriminatie-en-racisme/datasets/\"\n",
    "dataset_zoek = pd.read_csv(dataset_path + 'dataset_dummy.csv', sep = ',') # model is te groot om te trainen met volledige dataset zonder GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'document', 'text', 'zin', 'label', 'score_annotator',\n",
      "       'totaalscore'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>document</th>\n",
       "      <th>text</th>\n",
       "      <th>zin</th>\n",
       "      <th>label</th>\n",
       "      <th>score_annotator</th>\n",
       "      <th>totaalscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Beslisnota bij Kamerbrief over Geografische Ba...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>positief</td>\n",
       "      <td>0.449565</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Beslisnota bij Kamerbrief over Geografische Ba...</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>positief</td>\n",
       "      <td>0.125925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Beslisnota bij Kamerbrief over Geografische Ba...</td>\n",
       "      <td>...</td>\n",
       "      <td>t</td>\n",
       "      <td>positief</td>\n",
       "      <td>0.855116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Beslisnota bij Kamerbrief over Geografische Ba...</td>\n",
       "      <td>...</td>\n",
       "      <td>de\\n                          Subsidieregelin...</td>\n",
       "      <td>positief</td>\n",
       "      <td>0.909220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Beslisnota bij Kamerbrief over Geografische Ba...</td>\n",
       "      <td>...</td>\n",
       "      <td>l</td>\n",
       "      <td>positief</td>\n",
       "      <td>0.238765</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7177</th>\n",
       "      <td>7177</td>\n",
       "      <td>Agenda Natuurinclusief 2.0</td>\n",
       "      <td>We realiseren het ons niet dagelijks, maar nat...</td>\n",
       "      <td>\\n      VISUALISATIE COLLECTIEF NATUURINCLUSIE...</td>\n",
       "      <td>positief</td>\n",
       "      <td>0.223324</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7178</th>\n",
       "      <td>7178</td>\n",
       "      <td>Agenda Natuurinclusief 2.0</td>\n",
       "      <td>We realiseren het ons niet dagelijks, maar nat...</td>\n",
       "      <td>Wij zorgen voor een ‘vruchtbare bodem’ met co...</td>\n",
       "      <td>positief</td>\n",
       "      <td>0.317717</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7179</th>\n",
       "      <td>7179</td>\n",
       "      <td>Agenda Natuurinclusief 2.0</td>\n",
       "      <td>We realiseren het ons niet dagelijks, maar nat...</td>\n",
       "      <td>Dit doen we met ie-\\n      dereen samen</td>\n",
       "      <td>positief</td>\n",
       "      <td>0.761689</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7180</th>\n",
       "      <td>7180</td>\n",
       "      <td>Agenda Natuurinclusief 2.0</td>\n",
       "      <td>We realiseren het ons niet dagelijks, maar nat...</td>\n",
       "      <td>Zie de visualisatie van de beweging natuurinc...</td>\n",
       "      <td>positief</td>\n",
       "      <td>0.146005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7181</th>\n",
       "      <td>7181</td>\n",
       "      <td>Agenda Natuurinclusief 2.0</td>\n",
       "      <td>We realiseren het ons niet dagelijks, maar nat...</td>\n",
       "      <td>\\n                                            ...</td>\n",
       "      <td>positief</td>\n",
       "      <td>0.007847</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7182 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                           document  \\\n",
       "0              0  Beslisnota bij Kamerbrief over Geografische Ba...   \n",
       "1              1  Beslisnota bij Kamerbrief over Geografische Ba...   \n",
       "2              2  Beslisnota bij Kamerbrief over Geografische Ba...   \n",
       "3              3  Beslisnota bij Kamerbrief over Geografische Ba...   \n",
       "4              4  Beslisnota bij Kamerbrief over Geografische Ba...   \n",
       "...          ...                                                ...   \n",
       "7177        7177                         Agenda Natuurinclusief 2.0   \n",
       "7178        7178                         Agenda Natuurinclusief 2.0   \n",
       "7179        7179                         Agenda Natuurinclusief 2.0   \n",
       "7180        7180                         Agenda Natuurinclusief 2.0   \n",
       "7181        7181                         Agenda Natuurinclusief 2.0   \n",
       "\n",
       "                                                   text  \\\n",
       "0                                                   ...   \n",
       "1                                                   ...   \n",
       "2                                                   ...   \n",
       "3                                                   ...   \n",
       "4                                                   ...   \n",
       "...                                                 ...   \n",
       "7177  We realiseren het ons niet dagelijks, maar nat...   \n",
       "7178  We realiseren het ons niet dagelijks, maar nat...   \n",
       "7179  We realiseren het ons niet dagelijks, maar nat...   \n",
       "7180  We realiseren het ons niet dagelijks, maar nat...   \n",
       "7181  We realiseren het ons niet dagelijks, maar nat...   \n",
       "\n",
       "                                                    zin     label  \\\n",
       "0                                                   ...  positief   \n",
       "1                                                     b  positief   \n",
       "2                                                     t  positief   \n",
       "3      de\\n                          Subsidieregelin...  positief   \n",
       "4                                                     l  positief   \n",
       "...                                                 ...       ...   \n",
       "7177  \\n      VISUALISATIE COLLECTIEF NATUURINCLUSIE...  positief   \n",
       "7178   Wij zorgen voor een ‘vruchtbare bodem’ met co...  positief   \n",
       "7179            Dit doen we met ie-\\n      dereen samen  positief   \n",
       "7180   Zie de visualisatie van de beweging natuurinc...  positief   \n",
       "7181  \\n                                            ...  positief   \n",
       "\n",
       "      score_annotator  totaalscore  \n",
       "0            0.449565            0  \n",
       "1            0.125925            0  \n",
       "2            0.855116            1  \n",
       "3            0.909220            1  \n",
       "4            0.238765            0  \n",
       "...               ...          ...  \n",
       "7177         0.223324            0  \n",
       "7178         0.317717            0  \n",
       "7179         0.761689            1  \n",
       "7180         0.146005            0  \n",
       "7181         0.007847            0  \n",
       "\n",
       "[7182 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bekijken dataset\n",
    "print(dataset_zoek.columns)\n",
    "\n",
    "display(dataset_zoek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_zoek.drop(columns = ['Unnamed: 0', 'document', 'zin', 'label', 'score_annotator'])\n",
    "dataset = dataset.rename(columns={\"totaalscore\": \"label\", 'text': 'text'})\n",
    "\n",
    "# split dataset: 60% train, 20% val, 20% test\n",
    "train_val_df, test_df = train_test_split(dataset, test_size=0.20)\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at GroNLP/bert-base-dutch-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GroNLP/bert-base-dutch-cased and are newly initialized: ['bert.pooler.dense.bias', 'classifier.bias', 'classifier.weight', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# define hyperparameters\n",
    "train_args ={\"reprocess_input_data\": True,\n",
    "             \"fp16\":False,\n",
    "             \"overwrite_output_dir\": True,\n",
    "             \"num_train_epochs\": 4,\n",
    "             \"evaluate_during_training\": True,\n",
    "            \"evaluation_strategy\":\"steps\",\n",
    "            \"eval_steps\": 500}\n",
    "\n",
    "# Create a ClassificationModel\n",
    "model = ClassificationModel(\n",
    "    \"bert\", \"GroNLP/bert-base-dutch-cased\",\n",
    "    num_labels=2,\n",
    "    args=train_args,\n",
    "    use_cuda=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e32b65567994f6987063088cff91d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4308 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a711b80a0649ea9b6437b4035d19b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0968feb1b34c4a499e7c9b03ce8f168c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 4:   0%|          | 0/539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.train_model(train_df = train_df, eval_df = val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def f1_multiclass(labels, preds):\n",
    "    return f1_score(labels, preds, average='micro')\n",
    "\n",
    "result, model_outputs, wrong_predictions = model.eval_model(test_df, f1=f1_multiclass, acc=accuracy_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUDE/ANDERE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = dataset_zoek.drop(columns = ['Unnamed: 0', 'document', 'zin', 'label', 'score_annotator'])\n",
    "#dataset = dataset.rename(columns={\"totaalscore\": \"label\", 'text': 'text'})\n",
    "print(dataset.columns)\n",
    "\n",
    "\n",
    "X = list(dataset_zoek[\"text\"])\n",
    "y = list(dataset_zoek[\"totaalscore\"])\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = 0.25)\n",
    "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
    "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)\n",
    "X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_train = tokenizer(dataset['train'][\"text\"], return_tensors=\"np\", padding=True)\n",
    "# Tokenizer returns a BatchEncoding, but we convert that to a dict for Keras\n",
    "#tokenized_data = dict(tokenized_train)\n",
    "                     \n",
    "#labels_train = np.array(dataset['train'][\"label\"])  # Label is already an array of 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">13</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">__init__</span><span style=\"font-weight: bold\">()</span> got an unexpected keyword argument <span style=\"color: #008000; text-decoration-color: #008000\">'reprocess_input_data'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m13\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0m\u001b[1;35m__init__\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m got an unexpected keyword argument \u001b[32m'reprocess_input_data'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# trainen\n",
    "# sla training_arguments op\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    seed=0,\n",
    "    load_best_model_at_end=True,\n",
    "    reprocess_input_data= True,\n",
    "    fp16=False,\n",
    "    overwrite_output_dir = True\n",
    ")\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model!\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=val,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)\n",
    "\n",
    "classifier_model = build_classifier_model()\n",
    "bert_raw_result = classifier_model(tf.constant(text_test))\n",
    "print(tf.sigmoid(bert_raw_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maak dataset correcte format: [{'label': value, 'text': text}, {'label': value, 'text': text}]\n",
    "data = []\n",
    "\n",
    "for i in range(len(dataset_zoek)):\n",
    "    label = dataset_zoek['totaalscore'].iloc[i]\n",
    "    text = dataset_zoek['zin'].iloc[i]\n",
    "    tokenized_text = tokenizer(str(text), return_tensors=\"np\", padding=True)\n",
    "    duo = {'label': label, 'text': tokenized_text}\n",
    "    data.append(duo)\n",
    "    \n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset: 60% train, 20% val, 20% test\n",
    "trainval, test = train_test_split(data, train_size = 0.8)\n",
    "train, val = train_test_split(trainval, train_size = 0.75)\n",
    "\n",
    "print(len(train), len(val), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "\n",
    "for item in train:\n",
    "    train_labels.append(item['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "# Read data\n",
    "dataset_zoek = pd.read_csv(dataset_path + 'dataset_dummy.csv', sep = ',') # model is te groot om te trainen met volledige dataset zonder GPU\n",
    "dataset = dataset_zoek.drop(columns = ['Unnamed: 0', 'document', 'zin', 'label', 'score_annotator'])\n",
    "dataset = dataset.rename(columns={\"totaalscore\": \"label\", 'text': 'text'})\n",
    "\n",
    "# Define pretrained tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"GroNLP/bert-base-dutch-cased\")\n",
    "model = AutoModel.from_pretrained(\"GroNLP/bert-base-dutch-cased\")  # PyTorch\n",
    "\n",
    "# ----- 1. Preprocess data -----#\n",
    "# Preprocess data\n",
    "X = list(dataset_zoek[\"text\"])\n",
    "y = list(dataset_zoek[\"totaalscore\"])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
    "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create torch dataset\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "train_dataset = Dataset(X_train_tokenized, y_train)\n",
    "val_dataset = Dataset(X_val_tokenized, y_val)\n",
    "\n",
    "# ----- 2. Fine-tune pretrained model -----#\n",
    "# Define Trainer parameters\n",
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Trainer\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    seed=0,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")\n",
    "\n",
    "# Train pre-trained model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- 3. Predict -----#\n",
    "# Load test data\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "X_test = list(test_data[\"review\"])\n",
    "X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Create torch dataset\n",
    "test_dataset = Dataset(X_test_tokenized)\n",
    "\n",
    "# Load trained model\n",
    "model_path = \"output/checkpoint-50000\"\n",
    "model = BertForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "\n",
    "# Define test trainer\n",
    "test_trainer = Trainer(model)\n",
    "\n",
    "# Make prediction\n",
    "raw_pred, _, _ = test_trainer.predict(test_dataset)\n",
    "\n",
    "# Preprocess raw predictions\n",
    "y_pred = np.argmax(raw_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_pandas(dataset)\n",
    "\n",
    "print(ds)\n",
    "\n",
    "# split dataset: 60% train, 20% val, 20% test\n",
    "train_testvalid = ds.train_test_split(test_size=0.4)\n",
    "# Split the 40% test + valid in half test, half valid\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5)\n",
    "# gather everyone if you want to have a single DatasetDict\n",
    "ds = DatasetDict({\n",
    "    'train': train_testvalid['train'],\n",
    "    'test': test_valid['test'],\n",
    "    'valid': test_valid['train']})\n",
    "\n",
    "print(ds['train']['text'][100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=True,\n",
    "        return_dict=True,\n",
    "        tokenizer=None, \n",
    "        topic=None, \n",
    "        freeze_bert = None, \n",
    "        num_feats=None, \n",
    "        keep_stopwords = None,\n",
    "        combined_feats = None, \n",
    "        sum_layers = None\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "       \n",
    "        combined_feats=aggregate_features(outputs, tokenizer, input_ids, topic, \n",
    "                                     num_feats, keep_stopwords, sum_layers).to(device)\n",
    "        combined_feats = self.dropout(combined_feats)\n",
    "        logits = self.classifier(combined_feats)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataLabDisc",
   "language": "python",
   "name": "datalabdisc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
